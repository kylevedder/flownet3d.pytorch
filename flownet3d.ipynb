{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Manager\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import kaolin as kal\n",
    "from kaolin.models.PointNet2 import furthest_point_sampling\n",
    "from kaolin.models.PointNet2 import fps_gather_by_index\n",
    "from kaolin.models.PointNet2 import ball_query\n",
    "from kaolin.models.PointNet2 import group_gather_by_index\n",
    "from kaolin.models.PointNet2 import three_nn\n",
    "from kaolin.models.PointNet2 import three_interpolate\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048]) torch.float32\n",
      "torch.Size([3, 2048]) torch.float32\n",
      "torch.Size([3, 2048]) torch.float32\n",
      "torch.Size([3, 2048]) torch.float32\n",
      "torch.Size([3, 2048]) torch.float32\n",
      "torch.Size([2048]) torch.bool\n"
     ]
    }
   ],
   "source": [
    "class SceneflowDataset(Dataset):\n",
    "    def __init__(self, npoints=2048, root='data/data_processed_maxcut_35_20k_2k_8192', train=True, cache=None):\n",
    "        self.npoints = npoints\n",
    "        self.train = train\n",
    "        self.root = root\n",
    "        if self.train:\n",
    "            self.datapath = glob.glob(os.path.join(self.root, 'TRAIN*.npz'))\n",
    "        else:\n",
    "            self.datapath = glob.glob(os.path.join(self.root, 'TEST*.npz'))\n",
    "        \n",
    "        if cache is None:\n",
    "            self.cache = {}\n",
    "        else:\n",
    "            self.cache = cache\n",
    "        \n",
    "        self.cache_size = 30000\n",
    "\n",
    "        ###### deal with one bad datapoint with nan value\n",
    "        self.datapath = [d for d in self.datapath if 'TRAIN_C_0140_left_0006-0' not in d]\n",
    "        ######\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index in self.cache:\n",
    "            pos1, pos2, color1, color2, flow, mask1 = self.cache[index]\n",
    "        else:\n",
    "            fn = self.datapath[index]\n",
    "            with open(fn, 'rb') as fp:\n",
    "                data = np.load(fp)\n",
    "                pos1 = data['points1'].astype('float32')\n",
    "                pos2 = data['points2'].astype('float32')\n",
    "                color1 = data['color1'].astype('float32') / 255\n",
    "                color2 = data['color2'].astype('float32') / 255\n",
    "                flow = data['flow'].astype('float32')\n",
    "                mask1 = data['valid_mask1']\n",
    "\n",
    "            if len(self.cache) < self.cache_size:\n",
    "                self.cache[index] = (pos1, pos2, color1, color2, flow, mask1)\n",
    "\n",
    "        if self.train:\n",
    "            n1 = pos1.shape[0]\n",
    "            sample_idx1 = np.random.choice(n1, self.npoints, replace=False)\n",
    "            n2 = pos2.shape[0]\n",
    "            sample_idx2 = np.random.choice(n2, self.npoints, replace=False)\n",
    "\n",
    "            pos1 = pos1[sample_idx1, :]\n",
    "            pos2 = pos2[sample_idx2, :]\n",
    "            color1 = color1[sample_idx1, :]\n",
    "            color2 = color2[sample_idx2, :]\n",
    "            flow = flow[sample_idx1, :]\n",
    "            mask1 = mask1[sample_idx1]\n",
    "        else:\n",
    "            pos1 = pos1[:self.npoints, :]\n",
    "            pos2 = pos2[:self.npoints, :]\n",
    "            color1 = color1[:self.npoints, :]\n",
    "            color2 = color2[:self.npoints, :]\n",
    "            flow = flow[:self.npoints, :]\n",
    "            mask1 = mask1[:self.npoints]\n",
    "\n",
    "        pos1_center = np.mean(pos1, 0)\n",
    "        pos1 -= pos1_center\n",
    "        pos2 -= pos1_center\n",
    "        \n",
    "        pos1 = torch.from_numpy(pos1).t()\n",
    "        pos2 = torch.from_numpy(pos2).t()\n",
    "        color1 = torch.from_numpy(color1).t()\n",
    "        color2 = torch.from_numpy(color2).t()\n",
    "        flow = torch.from_numpy(flow).t()\n",
    "        mask1 = torch.from_numpy(mask1)\n",
    "\n",
    "        return pos1, pos2, color1, color2, flow, mask1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.datapath)\n",
    "    \n",
    "train_set = SceneflowDataset(train=True)\n",
    "points1, points2, color1, color2, flow, mask1 = train_set[0]\n",
    "\n",
    "print(points1.shape, points1.dtype)\n",
    "print(points2.shape, points2.dtype)\n",
    "print(color1.shape, color1.dtype)\n",
    "print(color2.shape, color2.dtype)\n",
    "print(flow.shape, flow.dtype)\n",
    "print(mask1.shape, mask1.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "def pdist2squared(x, y):\n",
    "    xx = (x**2).sum(dim=1).unsqueeze(2)\n",
    "    yy = (y**2).sum(dim=1).unsqueeze(1)\n",
    "    dist = xx + yy - 2.0 * torch.bmm(x.permute(0, 2, 1), y)\n",
    "    dist[dist != dist] = 0\n",
    "    dist = torch.clamp(dist, 0.0, np.inf)\n",
    "    return dist\n",
    "\n",
    "def parameter_count(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "class ClippedStepLR(optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, step_size, min_lr, gamma=0.1, last_epoch=-1):\n",
    "        self.step_size = step_size\n",
    "        self.min_lr = min_lr\n",
    "        self.gamma = gamma\n",
    "        super(ClippedStepLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [max(base_lr * self.gamma ** (self.last_epoch // self.step_size), self.min_lr)\n",
    "                for base_lr in self.base_lrs]\n",
    "    \n",
    "def criterion(pred_flow, flow, mask):\n",
    "    loss = torch.mean(mask * torch.sum((pred_flow - flow) * (pred_flow - flow), dim=1) / 2.0)\n",
    "    return loss\n",
    "\n",
    "def error(pred, labels, mask):\n",
    "    pred = pred.permute(0,2,1).cpu().numpy()\n",
    "    labels = labels.permute(0,2,1).cpu().numpy()\n",
    "    mask = mask.cpu().numpy()\n",
    "    \n",
    "    err = np.sqrt(np.sum((pred - labels)**2, 2) + 1e-20)\n",
    "\n",
    "    gtflow_len = np.sqrt(np.sum(labels*labels, 2) + 1e-20) # B,N\n",
    "    acc050 = np.sum(np.logical_or((err <= 0.05)*mask, (err/gtflow_len <= 0.05)*mask), axis=1)\n",
    "    acc010 = np.sum(np.logical_or((err <= 0.1)*mask, (err/gtflow_len <= 0.1)*mask), axis=1)\n",
    "\n",
    "    mask_sum = np.sum(mask, 1)\n",
    "    acc050 = acc050[mask_sum > 0] / mask_sum[mask_sum > 0]\n",
    "    acc050 = np.mean(acc050)\n",
    "    acc010 = acc010[mask_sum > 0] / mask_sum[mask_sum > 0]\n",
    "    acc010 = np.mean(acc010)\n",
    "\n",
    "    epe = np.sum(err * mask, 1)[mask_sum > 0] / mask_sum[mask_sum > 0]\n",
    "    epe = np.mean(epe)\n",
    "    return epe, acc050, acc010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample(nn.Module):\n",
    "    def __init__(self, num_points):\n",
    "        super(Sample, self).__init__()\n",
    "        \n",
    "        self.num_points = num_points\n",
    "        \n",
    "    def forward(self, points):\n",
    "        new_points_ind = furthest_point_sampling(points.permute(0, 2, 1).contiguous(), self.num_points)\n",
    "        new_points = fps_gather_by_index(points, new_points_ind)\n",
    "        return new_points\n",
    "    \n",
    "class Group(nn.Module):\n",
    "    def __init__(self, radius, num_samples, knn=False):\n",
    "        super(Group, self).__init__()\n",
    "        \n",
    "        self.radius = radius\n",
    "        self.num_samples = num_samples\n",
    "        self.knn = knn\n",
    "        \n",
    "    def forward(self, points, new_points, features):\n",
    "        if self.knn:\n",
    "            dist = pdist2squared(points, new_points)\n",
    "            ind = dist.topk(self.num_samples, dim=1, largest=False)[1].int().permute(0, 2, 1).contiguous()\n",
    "        else:\n",
    "            ind = ball_query(self.radius, self.num_samples, points.permute(0, 2, 1).contiguous(),\n",
    "                             new_points.permute(0, 2, 1).contiguous(), False)\n",
    "        grouped_points = group_gather_by_index(points, ind)\n",
    "        grouped_points -= new_points.unsqueeze(3)\n",
    "        grouped_features = group_gather_by_index(features, ind)\n",
    "        new_features = torch.cat([grouped_points, grouped_features], dim=1)\n",
    "        return new_features\n",
    "\n",
    "class SetConv(nn.Module):\n",
    "    def __init__(self, num_points, radius, num_samples, in_channels, out_channels):\n",
    "        super(SetConv, self).__init__()\n",
    "        \n",
    "        self.sample = Sample(num_points)\n",
    "        self.group = Group(radius, num_samples)\n",
    "        \n",
    "        layers = []\n",
    "        out_channels = [in_channels+3, *out_channels]\n",
    "        for i in range(1, len(out_channels)):\n",
    "            layers += [nn.Conv2d(out_channels[i - 1], out_channels[i], 1, bias=True), nn.BatchNorm2d(out_channels[i], eps=0.001), nn.ReLU()]\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, points, features):\n",
    "        new_points = self.sample(points)\n",
    "        new_features = self.group(points, new_points, features)\n",
    "        new_features = self.conv(new_features)\n",
    "        new_features = new_features.max(dim=3)[0]\n",
    "        return new_points, new_features\n",
    "    \n",
    "class FlowEmbedding(nn.Module):\n",
    "    def __init__(self, num_samples, in_channels, out_channels):\n",
    "        super(FlowEmbedding, self).__init__()\n",
    "        \n",
    "        self.num_samples = num_samples\n",
    "        \n",
    "        self.group = Group(None, self.num_samples, knn=True)\n",
    "        \n",
    "        layers = []\n",
    "        out_channels = [2*in_channels+3, *out_channels]\n",
    "        for i in range(1, len(out_channels)):\n",
    "            layers += [nn.Conv2d(out_channels[i - 1], out_channels[i], 1, bias=True), nn.BatchNorm2d(out_channels[i], eps=0.001), nn.ReLU()]\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, points1, points2, features1, features2):\n",
    "        new_features = self.group(points2, points1, features2)\n",
    "        new_features = torch.cat([new_features, features1.unsqueeze(3).expand(-1, -1, -1, self.num_samples)], dim=1)\n",
    "        new_features = self.conv(new_features)\n",
    "        new_features = new_features.max(dim=3)[0]\n",
    "        return new_features\n",
    "    \n",
    "class SetUpConv(nn.Module):\n",
    "    def __init__(self, num_samples, in_channels1, in_channels2, out_channels1, out_channels2):\n",
    "        super(SetUpConv, self).__init__()\n",
    "        \n",
    "        self.group = Group(None, num_samples, knn=True)\n",
    "        \n",
    "        layers = []\n",
    "        out_channels1 = [in_channels1+3, *out_channels1]\n",
    "        for i in range(1, len(out_channels1)):\n",
    "            layers += [nn.Conv2d(out_channels1[i - 1], out_channels1[i], 1, bias=True), nn.BatchNorm2d(out_channels1[i], eps=0.001), nn.ReLU()]\n",
    "        self.conv1 = nn.Sequential(*layers)\n",
    "        \n",
    "        layers = []\n",
    "        if len(out_channels1) == 1:\n",
    "            out_channels2 = [in_channels1+in_channels2+3, *out_channels2]\n",
    "        else:\n",
    "            out_channels2 = [out_channels1[-1]+in_channels2, *out_channels2]\n",
    "        for i in range(1, len(out_channels2)):\n",
    "            layers += [nn.Conv2d(out_channels2[i - 1], out_channels2[i], 1, bias=True), nn.BatchNorm2d(out_channels2[i], eps=0.001), nn.ReLU()]\n",
    "        self.conv2 = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, points1, points2, features1, features2):\n",
    "        new_features = self.group(points1, points2, features1)\n",
    "        new_features = self.conv1(new_features)\n",
    "        new_features = new_features.max(dim=3)[0]\n",
    "        new_features = torch.cat([new_features, features2], dim=1)\n",
    "        new_features = new_features.unsqueeze(3)\n",
    "        new_features = self.conv2(new_features)\n",
    "        new_features = new_features.squeeze(3)\n",
    "        return new_features\n",
    "    \n",
    "class FeaturePropagation(nn.Module):\n",
    "    def __init__(self, in_channels1, in_channels2, out_channels):\n",
    "        super(FeaturePropagation, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        out_channels = [in_channels1+in_channels2, *out_channels]\n",
    "        for i in range(1, len(out_channels)):\n",
    "            layers += [nn.Conv2d(out_channels[i - 1], out_channels[i], 1, bias=True), nn.BatchNorm2d(out_channels[i], eps=0.001), nn.ReLU()]\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, points1, points2, features1, features2):\n",
    "        dist, ind = three_nn(points2.permute(0, 2, 1).contiguous(), points1.permute(0, 2, 1).contiguous())\n",
    "        dist = dist * dist\n",
    "        dist[dist < 1e-10] = 1e-10\n",
    "        inverse_dist = 1.0 / dist\n",
    "        norm = torch.sum(inverse_dist, dim=2, keepdim=True)\n",
    "        weights = inverse_dist / norm\n",
    "        #new_features = three_interpolate(features1, ind, weights) # wrong gradients\n",
    "        new_features = torch.sum(group_gather_by_index(features1, ind) * weights.unsqueeze(1), dim = 3)\n",
    "        new_features = torch.cat([new_features, features2], dim=1)\n",
    "        new_features = self.conv(new_features.unsqueeze(3)).squeeze(3)\n",
    "        return new_features\n",
    "\n",
    "class FlowNet3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlowNet3D, self).__init__()\n",
    "        \n",
    "        self.set_conv1 = SetConv(1024, 0.5, 16, 3, [32, 32, 64])\n",
    "        self.set_conv2 = SetConv(256, 1.0, 16, 64, [64, 64, 128])\n",
    "        self.flow_embedding = FlowEmbedding(64, 128, [128, 128, 128])\n",
    "        self.set_conv3 = SetConv(64, 2.0, 8, 128, [128, 128, 256])\n",
    "        self.set_conv4 = SetConv(16, 4.0, 8, 256, [256, 256, 512])\n",
    "        self.set_upconv1 = SetUpConv(8, 512, 256, [], [256, 256])\n",
    "        self.set_upconv2 = SetUpConv(8, 256, 256, [128, 128, 256], [256])\n",
    "        self.set_upconv3 = SetUpConv(8, 256, 64, [128, 128, 256], [256])\n",
    "        self.fp = FeaturePropagation(256, 3, [256, 256])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv1d(256, 128, 1, bias=True),\n",
    "            nn.BatchNorm1d(128, eps=0.001),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 3, 1, bias=True)\n",
    "        )\n",
    "         \n",
    "    def forward(self, points1, points2, features1, features2):\n",
    "        points1_1, features1_1 = self.set_conv1(points1, features1)\n",
    "        points1_2, features1_2 = self.set_conv2(points1_1, features1_1)\n",
    "\n",
    "        points2_1, features2_1 = self.set_conv1(points2, features2)\n",
    "        points2_2, features2_2 = self.set_conv2(points2_1, features2_1)\n",
    "\n",
    "        embedding = self.flow_embedding(points1_2, points2_2, features1_2, features2_2)\n",
    "        \n",
    "        points1_3, features1_3 = self.set_conv3(points1_2, embedding)\n",
    "        points1_4, features1_4 = self.set_conv4(points1_3, features1_3)\n",
    "        \n",
    "        new_features1_3 = self.set_upconv1(points1_4, points1_3, features1_4, features1_3)\n",
    "        new_features1_2 = self.set_upconv2(points1_3, points1_2, new_features1_3, torch.cat([features1_2, embedding], dim=1))\n",
    "        new_features1_1 = self.set_upconv3(points1_2, points1_1, new_features1_2, features1_1)\n",
    "        new_features1 = self.fp(points1_1, points1, new_features1_1, features1)\n",
    "\n",
    "        flow = self.classifier(new_features1)\n",
    "        \n",
    "        return flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_path = os.path.abspath('/path/to/model.ckpt')\n",
    "init_vars = tf.train.list_variables(tf_path)\n",
    "tf_vars = {}\n",
    "for name, shape in init_vars:\n",
    "    array = tf.train.load_variable(tf_path, name)\n",
    "    tf_vars[name] = array\n",
    "\n",
    "mapping = {'fa_layer4/conv_0/biases' : 'fp.conv.0.bias',\n",
    "           'fa_layer4/conv_0/weights' : 'fp.conv.0.weight',\n",
    "           'fa_layer4/conv_0/bn/beta' : 'fp.conv.1.bias',\n",
    "           'fa_layer4/conv_0/bn/gamma' : 'fp.conv.1.weight',\n",
    "           'fa_layer4/conv_0/bn/moving_mean' : 'fp.conv.1.running_mean',\n",
    "           'fa_layer4/conv_0/bn/moving_variance' : 'fp.conv.1.running_var',\n",
    "           'fa_layer4/conv_1/biases' : 'fp.conv.3.bias',\n",
    "           'fa_layer4/conv_1/weights' : 'fp.conv.3.weight',\n",
    "           'fa_layer4/conv_1/bn/beta' : 'fp.conv.4.bias',\n",
    "           'fa_layer4/conv_1/bn/gamma' : 'fp.conv.4.weight',\n",
    "           'fa_layer4/conv_1/bn/moving_mean' : 'fp.conv.4.running_mean',\n",
    "           'fa_layer4/conv_1/bn/moving_variance' : 'fp.conv.4.running_var',\n",
    "           'fc1/biases' : 'classifier.0.bias',\n",
    "           'fc1/bn/beta' : 'classifier.1.bias',\n",
    "           'fc1/bn/gamma' : 'classifier.1.weight',\n",
    "           'fc1/bn/moving_mean' : 'classifier.1.running_mean',\n",
    "           'fc1/bn/moving_variance' : 'classifier.1.running_var',\n",
    "           'fc1/weights' : 'classifier.0.weight',\n",
    "           'fc2/biases' : 'classifier.3.bias',\n",
    "           'fc2/weights' : 'classifier.3.weight',\n",
    "           'flow_embedding/conv_diff_0/biases' : 'flow_embedding.conv.0.bias',\n",
    "           'flow_embedding/conv_diff_0/bn/beta' : 'flow_embedding.conv.1.bias',\n",
    "           'flow_embedding/conv_diff_0/bn/gamma' : 'flow_embedding.conv.1.weight',\n",
    "           'flow_embedding/conv_diff_0/bn/moving_mean' : 'flow_embedding.conv.1.running_mean',\n",
    "           'flow_embedding/conv_diff_0/bn/moving_variance' : 'flow_embedding.conv.1.running_var',\n",
    "           'flow_embedding/conv_diff_0/weights' : 'flow_embedding.conv.0.weight',\n",
    "           'flow_embedding/conv_diff_1/biases' : 'flow_embedding.conv.3.bias',\n",
    "           'flow_embedding/conv_diff_1/bn/beta' : 'flow_embedding.conv.4.bias',\n",
    "           'flow_embedding/conv_diff_1/bn/gamma' : 'flow_embedding.conv.4.weight',\n",
    "           'flow_embedding/conv_diff_1/bn/moving_mean' : 'flow_embedding.conv.4.running_mean',\n",
    "           'flow_embedding/conv_diff_1/bn/moving_variance' : 'flow_embedding.conv.4.running_var',\n",
    "           'flow_embedding/conv_diff_1/weights' : 'flow_embedding.conv.3.weight',\n",
    "           'flow_embedding/conv_diff_2/biases' : 'flow_embedding.conv.6.bias',\n",
    "           'flow_embedding/conv_diff_2/bn/beta' : 'flow_embedding.conv.7.bias',\n",
    "           'flow_embedding/conv_diff_2/bn/gamma' : 'flow_embedding.conv.7.weight',\n",
    "           'flow_embedding/conv_diff_2/bn/moving_mean' : 'flow_embedding.conv.7.running_mean',\n",
    "           'flow_embedding/conv_diff_2/bn/moving_variance' : 'flow_embedding.conv.7.running_var',\n",
    "           'flow_embedding/conv_diff_2/weights' : 'flow_embedding.conv.6.weight',\n",
    "           'layer3/conv0/biases' : 'set_conv3.conv.0.bias',\n",
    "           'layer3/conv0/bn/beta' : 'set_conv3.conv.1.bias',\n",
    "           'layer3/conv0/bn/gamma' : 'set_conv3.conv.1.weight',\n",
    "           'layer3/conv0/bn/moving_mean' : 'set_conv3.conv.1.running_mean',\n",
    "           'layer3/conv0/bn/moving_variance' : 'set_conv3.conv.1.running_var',\n",
    "           'layer3/conv0/weights' : 'set_conv3.conv.0.weight',\n",
    "           'layer3/conv1/biases' : 'set_conv3.conv.3.bias',\n",
    "           'layer3/conv1/bn/beta' : 'set_conv3.conv.4.bias',\n",
    "           'layer3/conv1/bn/gamma' : 'set_conv3.conv.4.weight',\n",
    "           'layer3/conv1/bn/moving_mean' : 'set_conv3.conv.4.running_mean',\n",
    "           'layer3/conv1/bn/moving_variance' : 'set_conv3.conv.4.running_var',\n",
    "           'layer3/conv1/weights' : 'set_conv3.conv.3.weight',\n",
    "           'layer3/conv2/biases' : 'set_conv3.conv.6.bias',\n",
    "           'layer3/conv2/bn/beta' : 'set_conv3.conv.7.bias',\n",
    "           'layer3/conv2/bn/gamma' : 'set_conv3.conv.7.weight',\n",
    "           'layer3/conv2/bn/moving_mean' : 'set_conv3.conv.7.running_mean',\n",
    "           'layer3/conv2/bn/moving_variance' : 'set_conv3.conv.7.running_var',\n",
    "           'layer3/conv2/weights' : 'set_conv3.conv.6.weight',\n",
    "           'layer4/conv0/biases' : 'set_conv4.conv.0.bias',\n",
    "           'layer4/conv0/bn/beta' : 'set_conv4.conv.1.bias',\n",
    "           'layer4/conv0/bn/gamma' : 'set_conv4.conv.1.weight',\n",
    "           'layer4/conv0/bn/moving_mean' : 'set_conv4.conv.1.running_mean',\n",
    "           'layer4/conv0/bn/moving_variance' : 'set_conv4.conv.1.running_var',\n",
    "           'layer4/conv0/weights' : 'set_conv4.conv.0.weight',\n",
    "           'layer4/conv1/biases' : 'set_conv4.conv.3.bias',\n",
    "           'layer4/conv1/bn/beta' : 'set_conv4.conv.4.bias',\n",
    "           'layer4/conv1/bn/gamma' : 'set_conv4.conv.4.weight',\n",
    "           'layer4/conv1/bn/moving_mean' : 'set_conv4.conv.4.running_mean',\n",
    "           'layer4/conv1/bn/moving_variance' : 'set_conv4.conv.4.running_var',\n",
    "           'layer4/conv1/weights' : 'set_conv4.conv.3.weight',\n",
    "           'layer4/conv2/biases' : 'set_conv4.conv.6.bias',\n",
    "           'layer4/conv2/bn/beta' : 'set_conv4.conv.7.bias',\n",
    "           'layer4/conv2/bn/gamma' : 'set_conv4.conv.7.weight',\n",
    "           'layer4/conv2/bn/moving_mean' : 'set_conv4.conv.7.running_mean',\n",
    "           'layer4/conv2/bn/moving_variance' : 'set_conv4.conv.7.running_var',\n",
    "           'layer4/conv2/weights' : 'set_conv4.conv.6.weight',\n",
    "           'sa1/layer1/conv0/biases' : 'set_conv1.conv.0.bias',\n",
    "           'sa1/layer1/conv0/bn/beta' : 'set_conv1.conv.1.bias',\n",
    "           'sa1/layer1/conv0/bn/gamma' : 'set_conv1.conv.1.weight',\n",
    "           'sa1/layer1/conv0/bn/moving_mean' : 'set_conv1.conv.1.running_mean',\n",
    "           'sa1/layer1/conv0/bn/moving_variance' : 'set_conv1.conv.1.running_var',\n",
    "           'sa1/layer1/conv0/weights' : 'set_conv1.conv.0.weight',\n",
    "           'sa1/layer1/conv1/biases' : 'set_conv1.conv.3.bias',\n",
    "           'sa1/layer1/conv1/bn/beta' : 'set_conv1.conv.4.bias',\n",
    "           'sa1/layer1/conv1/bn/gamma' : 'set_conv1.conv.4.weight',\n",
    "           'sa1/layer1/conv1/bn/moving_mean' : 'set_conv1.conv.4.running_mean',\n",
    "           'sa1/layer1/conv1/bn/moving_variance' : 'set_conv1.conv.4.running_var',\n",
    "           'sa1/layer1/conv1/weights' : 'set_conv1.conv.3.weight',\n",
    "           'sa1/layer1/conv2/biases' : 'set_conv1.conv.6.bias',\n",
    "           'sa1/layer1/conv2/bn/beta' : 'set_conv1.conv.7.bias',\n",
    "           'sa1/layer1/conv2/bn/gamma' : 'set_conv1.conv.7.weight',\n",
    "           'sa1/layer1/conv2/bn/moving_mean' : 'set_conv1.conv.7.running_mean',\n",
    "           'sa1/layer1/conv2/bn/moving_variance' : 'set_conv1.conv.7.running_var',\n",
    "           'sa1/layer1/conv2/weights' : 'set_conv1.conv.6.weight',\n",
    "           'sa1/layer2/conv0/biases' : 'set_conv2.conv.0.bias',\n",
    "           'sa1/layer2/conv0/bn/beta' : 'set_conv2.conv.1.bias',\n",
    "           'sa1/layer2/conv0/bn/gamma' : 'set_conv2.conv.1.weight',\n",
    "           'sa1/layer2/conv0/bn/moving_mean' : 'set_conv2.conv.1.running_mean',\n",
    "           'sa1/layer2/conv0/bn/moving_variance' : 'set_conv2.conv.1.running_var',\n",
    "           'sa1/layer2/conv0/weights' : 'set_conv2.conv.0.weight',\n",
    "           'sa1/layer2/conv1/biases' : 'set_conv2.conv.3.bias',\n",
    "           'sa1/layer2/conv1/bn/beta' : 'set_conv2.conv.4.bias',\n",
    "           'sa1/layer2/conv1/bn/gamma' : 'set_conv2.conv.4.weight',\n",
    "           'sa1/layer2/conv1/bn/moving_mean' : 'set_conv2.conv.4.running_mean',\n",
    "           'sa1/layer2/conv1/bn/moving_variance' : 'set_conv2.conv.4.running_var',\n",
    "           'sa1/layer2/conv1/weights' : 'set_conv2.conv.3.weight',\n",
    "           'sa1/layer2/conv2/biases' : 'set_conv2.conv.6.bias',\n",
    "           'sa1/layer2/conv2/bn/beta' : 'set_conv2.conv.7.bias',\n",
    "           'sa1/layer2/conv2/bn/gamma' : 'set_conv2.conv.7.weight',\n",
    "           'sa1/layer2/conv2/bn/moving_mean' : 'set_conv2.conv.7.running_mean',\n",
    "           'sa1/layer2/conv2/bn/moving_variance' : 'set_conv2.conv.7.running_var',\n",
    "           'sa1/layer2/conv2/weights' : 'set_conv2.conv.6.weight',\n",
    "           'up_sa_layer1/post-conv0/biases' : 'set_upconv1.conv2.0.bias',\n",
    "           'up_sa_layer1/post-conv0/bn/beta' : 'set_upconv1.conv2.1.bias',\n",
    "           'up_sa_layer1/post-conv0/bn/gamma' : 'set_upconv1.conv2.1.weight',\n",
    "           'up_sa_layer1/post-conv0/bn/moving_mean' : 'set_upconv1.conv2.1.running_mean',\n",
    "           'up_sa_layer1/post-conv0/bn/moving_variance' : 'set_upconv1.conv2.1.running_var',\n",
    "           'up_sa_layer1/post-conv0/weights' : 'set_upconv1.conv2.0.weight',\n",
    "           'up_sa_layer1/post-conv1/biases' : 'set_upconv1.conv2.3.bias',\n",
    "           'up_sa_layer1/post-conv1/bn/beta' : 'set_upconv1.conv2.4.bias',\n",
    "           'up_sa_layer1/post-conv1/bn/gamma' : 'set_upconv1.conv2.4.weight',\n",
    "           'up_sa_layer1/post-conv1/bn/moving_mean' : 'set_upconv1.conv2.4.running_mean',\n",
    "           'up_sa_layer1/post-conv1/bn/moving_variance' : 'set_upconv1.conv2.4.running_var',\n",
    "           'up_sa_layer1/post-conv1/weights' : 'set_upconv1.conv2.3.weight',\n",
    "           'up_sa_layer2/conv0/biases' : 'set_upconv2.conv1.0.bias',\n",
    "           'up_sa_layer2/conv0/bn/beta' : 'set_upconv2.conv1.1.bias',\n",
    "           'up_sa_layer2/conv0/bn/gamma' : 'set_upconv2.conv1.1.weight',\n",
    "           'up_sa_layer2/conv0/bn/moving_mean' : 'set_upconv2.conv1.1.running_mean',\n",
    "           'up_sa_layer2/conv0/bn/moving_variance' : 'set_upconv2.conv1.1.running_var',\n",
    "           'up_sa_layer2/conv0/weights' : 'set_upconv2.conv1.0.weight',\n",
    "           'up_sa_layer2/conv1/biases' : 'set_upconv2.conv1.3.bias',\n",
    "           'up_sa_layer2/conv1/bn/beta' : 'set_upconv2.conv1.4.bias',\n",
    "           'up_sa_layer2/conv1/bn/gamma' : 'set_upconv2.conv1.4.weight',\n",
    "           'up_sa_layer2/conv1/bn/moving_mean' : 'set_upconv2.conv1.4.running_mean',\n",
    "           'up_sa_layer2/conv1/bn/moving_variance' : 'set_upconv2.conv1.4.running_var',\n",
    "           'up_sa_layer2/conv1/weights' : 'set_upconv2.conv1.3.weight',\n",
    "           'up_sa_layer2/conv2/biases' : 'set_upconv2.conv1.6.bias',\n",
    "           'up_sa_layer2/conv2/bn/beta' : 'set_upconv2.conv1.7.bias',\n",
    "           'up_sa_layer2/conv2/bn/gamma' : 'set_upconv2.conv1.7.weight',\n",
    "           'up_sa_layer2/conv2/bn/moving_mean' : 'set_upconv2.conv1.7.running_mean',\n",
    "           'up_sa_layer2/conv2/bn/moving_variance' : 'set_upconv2.conv1.7.running_var',\n",
    "           'up_sa_layer2/conv2/weights' : 'set_upconv2.conv1.6.weight',\n",
    "           'up_sa_layer2/post-conv0/biases' : 'set_upconv2.conv2.0.bias',\n",
    "           'up_sa_layer2/post-conv0/bn/beta' : 'set_upconv2.conv2.1.bias',\n",
    "           'up_sa_layer2/post-conv0/bn/gamma' : 'set_upconv2.conv2.1.weight',\n",
    "           'up_sa_layer2/post-conv0/bn/moving_mean' : 'set_upconv2.conv2.1.running_mean',\n",
    "           'up_sa_layer2/post-conv0/bn/moving_variance' : 'set_upconv2.conv2.1.running_var',\n",
    "           'up_sa_layer2/post-conv0/weights' : 'set_upconv2.conv2.0.weight',\n",
    "           'up_sa_layer3/conv0/biases' : 'set_upconv3.conv1.0.bias',\n",
    "           'up_sa_layer3/conv0/bn/beta' : 'set_upconv3.conv1.1.bias',\n",
    "           'up_sa_layer3/conv0/bn/gamma' : 'set_upconv3.conv1.1.weight',\n",
    "           'up_sa_layer3/conv0/bn/moving_mean' : 'set_upconv3.conv1.1.running_mean',\n",
    "           'up_sa_layer3/conv0/bn/moving_variance' : 'set_upconv3.conv1.1.running_var',\n",
    "           'up_sa_layer3/conv0/weights' : 'set_upconv3.conv1.0.weight',\n",
    "           'up_sa_layer3/conv1/biases' : 'set_upconv3.conv1.3.bias',\n",
    "           'up_sa_layer3/conv1/bn/beta' : 'set_upconv3.conv1.4.bias',\n",
    "           'up_sa_layer3/conv1/bn/gamma' : 'set_upconv3.conv1.4.weight',\n",
    "           'up_sa_layer3/conv1/bn/moving_mean' : 'set_upconv3.conv1.4.running_mean',\n",
    "           'up_sa_layer3/conv1/bn/moving_variance' : 'set_upconv3.conv1.4.running_var',\n",
    "           'up_sa_layer3/conv1/weights' : 'set_upconv3.conv1.3.weight',\n",
    "           'up_sa_layer3/conv2/biases' : 'set_upconv3.conv1.6.bias',\n",
    "           'up_sa_layer3/conv2/bn/beta' : 'set_upconv3.conv1.7.bias',\n",
    "           'up_sa_layer3/conv2/bn/gamma' : 'set_upconv3.conv1.7.weight',\n",
    "           'up_sa_layer3/conv2/bn/moving_mean' : 'set_upconv3.conv1.7.running_mean',\n",
    "           'up_sa_layer3/conv2/bn/moving_variance' : 'set_upconv3.conv1.7.running_var',\n",
    "           'up_sa_layer3/conv2/weights' : 'set_upconv3.conv1.6.weight',\n",
    "           'up_sa_layer3/post-conv0/biases' : 'set_upconv3.conv2.0.bias',\n",
    "           'up_sa_layer3/post-conv0/bn/beta' : 'set_upconv3.conv2.1.bias',\n",
    "           'up_sa_layer3/post-conv0/bn/gamma' : 'set_upconv3.conv2.1.weight',\n",
    "           'up_sa_layer3/post-conv0/bn/moving_mean' : 'set_upconv3.conv2.1.running_mean',\n",
    "           'up_sa_layer3/post-conv0/bn/moving_variance' : 'set_upconv3.conv2.1.running_var',\n",
    "           'up_sa_layer3/post-conv0/weights' : 'set_upconv3.conv2.0.weight',\n",
    "          }\n",
    "mapping=dict([reversed(i) for i in mapping.items()])\n",
    "\n",
    "state_dict = FlowNet3D().state_dict()\n",
    "for key, _ in state_dict.items():\n",
    "    if not state_dict[key].shape:\n",
    "        continue\n",
    "    elif len(state_dict[key].shape) == 4:\n",
    "        state_dict[key][:, :, :, :] = torch.from_numpy(tf_vars[mapping[key]]).permute(3, 2, 0, 1)\n",
    "        if 'flow_embedding.conv.0' in key:\n",
    "            temp = state_dict[key][:, -3:, :, :].clone()\n",
    "            state_dict[key][:, 3:, :, :] = state_dict[key][:, :-3, :, :].clone()\n",
    "            state_dict[key][:, :3, :, :] = temp\n",
    "        if 'set_upconv1.conv2.0' in key:\n",
    "            temp = state_dict[key][:, 512:515, :, :].clone()\n",
    "            state_dict[key][:, 3:515, :, :] = state_dict[key][:, :512, :, :].clone()\n",
    "            state_dict[key][:, :3, :, :] = temp\n",
    "        if 'set_upconv2.conv1.0' in key:\n",
    "            temp = state_dict[key][:, 256:259, :, :].clone()\n",
    "            state_dict[key][:, 3:259, :, :] = state_dict[key][:, :256, :, :].clone()\n",
    "            state_dict[key][:, :3, :, :] = temp\n",
    "        if 'set_upconv3.conv1.0' in key:\n",
    "            temp = state_dict[key][:, 256:259, :, :].clone()\n",
    "            state_dict[key][:, 3:259, :, :] = state_dict[key][:, :256, :, :].clone()\n",
    "            state_dict[key][:, :3, :, :] = temp\n",
    "    elif len(state_dict[key].shape) == 3:\n",
    "        state_dict[key][:, :, :] = torch.from_numpy(tf_vars[mapping[key]]).permute(2, 1, 0)\n",
    "    elif len(state_dict[key].shape) == 1:\n",
    "        state_dict[key][:] = torch.from_numpy(tf_vars[mapping[key]])\n",
    "           \n",
    "torch.save(state_dict, 'models/net_tf.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set: 2007 samples / 125 mini-batches\n",
      "mean loss: 0.024514434352517128\n",
      "mean epe: 0.14857300339009882\n",
      "mean acc050: 0.28733477243061456\n",
      "mean acc010: 0.6192634478202645\n",
      "---\n",
      "CPU times: user 1min 6s, sys: 25.7 s, total: 1min 32s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# data\n",
    "test_set = SceneflowDataset(train=False)\n",
    "test_loader = DataLoader(test_set,\n",
    "                         batch_size=16,\n",
    "                         num_workers=4,\n",
    "                         pin_memory=True,\n",
    "                         drop_last=True)\n",
    "\n",
    "print('test set:', len(test_set), 'samples /', len(test_loader), 'mini-batches')\n",
    "\n",
    "# model\n",
    "net = FlowNet3D().cuda()\n",
    "net.load_state_dict(torch.load('models/net_tf.pth'))\n",
    "net.eval()\n",
    "\n",
    "# statistics\n",
    "loss_sum = 0\n",
    "epe_sum = 0\n",
    "acc050_sum = 0\n",
    "acc010_sum = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # for each mini-batch\n",
    "    for points1, points2, features1, features2, flow, mask1 in test_loader:\n",
    "            \n",
    "        # to GPU\n",
    "        points1 = points1.cuda(non_blocking=True)\n",
    "        points2 = points2.cuda(non_blocking=True)\n",
    "        features1 = features1.cuda(non_blocking=True)\n",
    "        features2 = features2.cuda(non_blocking=True)\n",
    "        flow = flow.cuda(non_blocking=True)\n",
    "        mask1 = mask1.cuda(non_blocking=True)\n",
    "    \n",
    "        pred_flow_sum = torch.zeros(16, 3, 2048).cuda(non_blocking=True)\n",
    "        \n",
    "        # resample 10 times\n",
    "        for i in range(10):\n",
    "            \n",
    "            perm = torch.randperm(points1.shape[2])\n",
    "            points1_perm = points1[:, :, perm]\n",
    "            points2_perm = points2[:, :, perm]\n",
    "            features1_perm = features1[:, :, perm]\n",
    "            features2_perm = features2[:, :, perm]\n",
    "\n",
    "            # forward\n",
    "            pred_flow = net(points1_perm, points2_perm, features1_perm, features2_perm)\n",
    "            pred_flow_sum[:, :, perm] += pred_flow\n",
    "            pred_flow_sum=pred_flow_sum\n",
    "        \n",
    "        # statistics\n",
    "        pred_flow_sum /= 10\n",
    "        loss = criterion(pred_flow_sum, flow, mask1)\n",
    "        loss_sum += loss.item()\n",
    "        epe, acc050, acc010 = error(pred_flow_sum, flow, mask1)\n",
    "        epe_sum += epe\n",
    "        acc050_sum += acc050\n",
    "        acc010_sum += acc010\n",
    "        \n",
    "print('mean loss:', loss_sum/len(test_loader))\n",
    "print('mean epe:', epe_sum/len(test_loader))\n",
    "print('mean acc050:', acc050_sum/len(test_loader))\n",
    "print('mean acc010:', acc010_sum/len(test_loader))\n",
    "    \n",
    "print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "BATCH_SIZE = 16\n",
    "NUM_POINTS = 2048\n",
    "NUM_EPOCHS = 150\n",
    "INIT_LR = 0.001\n",
    "MIN_LR = 0.00001\n",
    "STEP_SIZE_LR = 10\n",
    "GAMMA_LR = 0.7\n",
    "INIT_BN_MOMENTUM = 0.5\n",
    "MIN_BN_MOMENTUM = 0.01\n",
    "STEP_SIZE_BN_MOMENTUM = 10\n",
    "GAMMA_BN_MOMENTUM = 0.5\n",
    "\n",
    "# data\n",
    "train_manager = Manager()\n",
    "train_cache = train_manager.dict()\n",
    "train_dataset = SceneflowDataset(npoints=NUM_POINTS, train=True, cache=train_cache)\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True,\n",
    "                          pin_memory=True,\n",
    "                          drop_last=True)\n",
    "print('train:', len(train_dataset), '/', len(train_loader))\n",
    "\n",
    "test_manager = Manager()\n",
    "test_cache = test_manager.dict()\n",
    "test_dataset = SceneflowDataset(npoints=NUM_POINTS, train=False, cache=test_cache)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        num_workers=4,\n",
    "                        pin_memory=True,\n",
    "                        drop_last=True)\n",
    "print('test:', len(test_dataset), '/', len(test_loader))\n",
    "\n",
    "# net\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv1d) or isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.0)\n",
    "    elif isinstance(m, nn.BatchNorm1d) or isinstance(m, nn.BatchNorm2d):\n",
    "        m.weight.data.fill_(1.0)\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "net = FlowNet3D().cuda()\n",
    "net.apply(init_weights)\n",
    "print('# parameters: ', parameter_count(net))\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=INIT_LR)\n",
    "\n",
    "# learning rate scheduler\n",
    "lr_scheduler = ClippedStepLR(optimizer, STEP_SIZE_LR, MIN_LR, GAMMA_LR)\n",
    "\n",
    "# batch norm momentum scheduler\n",
    "def update_bn_momentum(epoch):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.BatchNorm1d) or isinstance(m, nn.BatchNorm2d):\n",
    "            m.momentum = max(INIT_BN_MOMENTUM * GAMMA_BN_MOMENTUM ** (epoch // STEP_SIZE_BN_MOMENTUM), MIN_BN_MOMENTUM)\n",
    "\n",
    "# statistics\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "\n",
    "# for num_epochs\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    # update batch norm momentum\n",
    "    update_bn_momentum(epoch)\n",
    "    \n",
    "    # train mode\n",
    "    net.train()\n",
    "    \n",
    "    # statistics\n",
    "    running_loss = 0.0\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # for each mini-batch\n",
    "    for points1, points2, features1, features2, flow, mask1 in train_loader:\n",
    "        # to GPU\n",
    "        points1 = points1.cuda(non_blocking=True)\n",
    "        points2 = points2.cuda(non_blocking=True)\n",
    "        features1 = features1.cuda(non_blocking=True)\n",
    "        features2 = features2.cuda(non_blocking=True)\n",
    "        flow = flow.cuda(non_blocking=True)\n",
    "        mask1 = mask1.cuda(non_blocking=True)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        pred_flow = net(points1, points2, features1, features2)\n",
    "        loss = criterion(pred_flow, flow, mask1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # statistics\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "    \n",
    "    running_loss /= (len(train_loader))\n",
    "    \n",
    "    losses_train.append(running_loss)\n",
    "    \n",
    "    # output\n",
    "    print('Epoch {} (train) -- loss: {:.6f} -- duration (epoch/iteration): {:.4f} min/{:.4f} sec'.format(epoch, running_loss, (end_time-start_time)/60.0, (end_time-start_time)/len(train_loader)))\n",
    "    \n",
    "    # validate\n",
    "    with torch.no_grad():\n",
    "      \n",
    "        # eval mode\n",
    "        net.eval()\n",
    "\n",
    "        # statistics\n",
    "        running_loss = 0.0\n",
    "        torch.cuda.synchronize()\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # for each mini-batch\n",
    "        for points1, points2, features1, features2, flow, mask1 in test_loader:\n",
    "            \n",
    "            # to GPU\n",
    "            points1 = points1.cuda(non_blocking=True)\n",
    "            points2 = points2.cuda(non_blocking=True)\n",
    "            features1 = features1.cuda(non_blocking=True)\n",
    "            features2 = features2.cuda(non_blocking=True)\n",
    "            flow = flow.cuda(non_blocking=True)\n",
    "            mask1 = mask1.cuda(non_blocking=True)\n",
    "\n",
    "            # forward\n",
    "            pred_flow = net(points1, points2, features1, features2)\n",
    "            loss = criterion(pred_flow, flow, mask1)\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        torch.cuda.synchronize()\n",
    "        end_time = time.time()\n",
    "\n",
    "        running_loss /= len(test_loader)\n",
    "\n",
    "        losses_test.append(running_loss)\n",
    "\n",
    "        # output\n",
    "        print('Epoch {} (test) -- loss: {:.6f} -- duration (epoch/iteration): {:.4f} min/{:.4f} sec'.format(epoch, running_loss, (end_time-start_time)/60.0, (end_time-start_time)/len(train_loader)))\n",
    "        \n",
    "    # update learning rate\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    print('---')\n",
    "    \n",
    "plt.plot(losses_train)\n",
    "plt.plot(losses_test)\n",
    "\n",
    "net = net.cpu()\n",
    "torch.save(net.state_dict(),'models/net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set: 2007 samples / 125 mini-batches\n",
      "mean loss: 0.022257591910660266\n",
      "mean epe: 0.1463848694865201\n",
      "mean acc050: 0.28563897619579187\n",
      "mean acc010: 0.622624611406866\n",
      "---\n",
      "CPU times: user 1min 4s, sys: 25 s, total: 1min 29s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# data\n",
    "test_set = SceneflowDataset(train=False)\n",
    "test_loader = DataLoader(test_set,\n",
    "                         batch_size=16,\n",
    "                         num_workers=4,\n",
    "                         pin_memory=True,\n",
    "                         drop_last=True)\n",
    "\n",
    "print('test set:', len(test_set), 'samples /', len(test_loader), 'mini-batches')\n",
    "\n",
    "# model\n",
    "net = FlowNet3D().cuda()\n",
    "net.load_state_dict(torch.load('models/net.pth'))\n",
    "net.eval()\n",
    "\n",
    "# statistics\n",
    "loss_sum = 0\n",
    "epe_sum = 0\n",
    "acc050_sum = 0\n",
    "acc010_sum = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # for each mini-batch\n",
    "    for points1, points2, features1, features2, flow, mask1 in test_loader:\n",
    "            \n",
    "        # to GPU\n",
    "        points1 = points1.cuda(non_blocking=True)\n",
    "        points2 = points2.cuda(non_blocking=True)\n",
    "        features1 = features1.cuda(non_blocking=True)\n",
    "        features2 = features2.cuda(non_blocking=True)\n",
    "        flow = flow.cuda(non_blocking=True)\n",
    "        mask1 = mask1.cuda(non_blocking=True)\n",
    "    \n",
    "        pred_flow_sum = torch.zeros(16, 3, 2048).cuda(non_blocking=True)\n",
    "        \n",
    "        # resample 10 times\n",
    "        for i in range(10):\n",
    "            \n",
    "            perm = torch.randperm(points1.shape[2])\n",
    "            points1_perm = points1[:, :, perm]\n",
    "            points2_perm = points2[:, :, perm]\n",
    "            features1_perm = features1[:, :, perm]\n",
    "            features2_perm = features2[:, :, perm]\n",
    "\n",
    "            # forward\n",
    "            pred_flow = net(points1_perm, points2_perm, features1_perm, features2_perm)\n",
    "            pred_flow_sum[:, :, perm] += pred_flow\n",
    "        \n",
    "        # statistics\n",
    "        pred_flow_sum /= 10\n",
    "        loss = criterion(pred_flow_sum, flow, mask1)\n",
    "        loss_sum += loss.item()\n",
    "        epe, acc050, acc010 = error(pred_flow_sum, flow, mask1)\n",
    "        epe_sum += epe\n",
    "        acc050_sum += acc050\n",
    "        acc010_sum += acc010\n",
    "        \n",
    "print('mean loss:', loss_sum/len(test_loader))\n",
    "print('mean epe:', epe_sum/len(test_loader))\n",
    "print('mean acc050:', acc050_sum/len(test_loader))\n",
    "print('mean acc010:', acc010_sum/len(test_loader))\n",
    "    \n",
    "print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
